//go:build !noasm && amd64
// Code generated by gocc devel -- DO NOT EDIT.
//
// Source file         : test_simd_mul.c
// Clang version       : Apple clang version 16.0.0 (clang-1600.0.26.3)
// Target architecture : amd64
// Compiler options    : -mavx -mfma -mavx512f -mavx512dq

#include "textflag.h"

DATA LCPI0_0<>+0x00(SB)/2, $0x00ff
DATA LCPI0_0<>+0x02(SB)/2, $0x00ff
DATA LCPI0_0<>+0x04(SB)/2, $0x00ff
DATA LCPI0_0<>+0x06(SB)/2, $0x00ff
DATA LCPI0_0<>+0x08(SB)/2, $0x00ff
DATA LCPI0_0<>+0x0a(SB)/2, $0x00ff
DATA LCPI0_0<>+0x0c(SB)/2, $0x00ff
DATA LCPI0_0<>+0x0e(SB)/2, $0x00ff
DATA LCPI0_0<>+0x10(SB)/2, $0x00ff
DATA LCPI0_0<>+0x12(SB)/2, $0x00ff
DATA LCPI0_0<>+0x14(SB)/2, $0x00ff
DATA LCPI0_0<>+0x16(SB)/2, $0x00ff
DATA LCPI0_0<>+0x18(SB)/2, $0x00ff
DATA LCPI0_0<>+0x1a(SB)/2, $0x00ff
DATA LCPI0_0<>+0x1c(SB)/2, $0x00ff
DATA LCPI0_0<>+0x1e(SB)/2, $0x00ff
GLOBL LCPI0_0<>(SB), (RODATA|NOPTR), $32

DATA LCPI0_1<>+0x00(SB)/2, $0x00ff
GLOBL LCPI0_1<>(SB), (RODATA|NOPTR), $2

TEXT Â·uint8_simd_mul_avx512(SB), NOSPLIT, $0-32
	MOVQ input1+0(FP), DI
	MOVQ input2+8(FP), SI
	MOVQ output+16(FP), DX
	MOVQ size+24(FP), CX
	WORD $0xc985             // TESTL CX, CX                         // test	ecx, ecx
	JLE  LBB0_19             // <--                                  // jle	.LBB0_19
	NOP                      // (skipped)                            // push	rbp
	NOP                      // (skipped)                            // mov	rbp, rsp
	NOP                      // (skipped)                            // and	rsp, -8
	WORD $0x8941; BYTE $0xc8 // MOVL CX, R8                          // mov	r8d, ecx
	CMPQ R8, $0x20           // <--                                  // cmp	r8, 32
	JAE  LBB0_3              // <--                                  // jae	.LBB0_3
	XORL R9, R9              // <--                                  // xor	r9d, r9d

LBB0_14:
	WORD $0x2944; BYTE $0xc9 // SUBL R9, CX                          // sub	ecx, r9d
	MOVQ R9, R10             // <--                                  // mov	r10, r9
	NOTQ R10                 // <--                                  // not	r10
	ADDQ R8, R10             // <--                                  // add	r10, r8
	WORD $0xe183; BYTE $0x03 // ANDL $0x3, CX                        // and	ecx, 3
	JE   LBB0_16             // <--                                  // je	.LBB0_16

LBB0_15:
	LONG $0x04b60f42; BYTE $0x0e // MOVZX 0(SI)(R9*1), AX                // movzx	eax, byte ptr [rsi + r9]
	MULB 0(DI)(R9*1)             // <--                                  // mul	byte ptr [rdi + r9]
	MOVB AL, 0(DX)(R9*1)         // <--                                  // mov	byte ptr [rdx + r9], al
	INCQ R9                      // <--                                  // inc	r9
	DECQ CX                      // <--                                  // dec	rcx
	JNE  LBB0_15                 // <--                                  // jne	.LBB0_15

LBB0_16:
	CMPQ R10, $0x3 // <--                                  // cmp	r10, 3
	JB   LBB0_18   // <--                                  // jb	.LBB0_18

LBB0_17:
	LONG $0x04b60f42; BYTE $0x0e   // MOVZX 0(SI)(R9*1), AX                // movzx	eax, byte ptr [rsi + r9]
	MULB 0(DI)(R9*1)               // <--                                  // mul	byte ptr [rdi + r9]
	MOVB AL, 0(DX)(R9*1)           // <--                                  // mov	byte ptr [rdx + r9], al
	LONG $0x44b60f42; WORD $0x010e // MOVZX 0x1(SI)(R9*1), AX              // movzx	eax, byte ptr [rsi + r9 + 1]
	MULB 0x1(DI)(R9*1)             // <--                                  // mul	byte ptr [rdi + r9 + 1]
	MOVB AL, 0x1(DX)(R9*1)         // <--                                  // mov	byte ptr [rdx + r9 + 1], al
	LONG $0x44b60f42; WORD $0x020e // MOVZX 0x2(SI)(R9*1), AX              // movzx	eax, byte ptr [rsi + r9 + 2]
	MULB 0x2(DI)(R9*1)             // <--                                  // mul	byte ptr [rdi + r9 + 2]
	MOVB AL, 0x2(DX)(R9*1)         // <--                                  // mov	byte ptr [rdx + r9 + 2], al
	LONG $0x44b60f42; WORD $0x030e // MOVZX 0x3(SI)(R9*1), AX              // movzx	eax, byte ptr [rsi + r9 + 3]
	MULB 0x3(DI)(R9*1)             // <--                                  // mul	byte ptr [rdi + r9 + 3]
	MOVB AL, 0x3(DX)(R9*1)         // <--                                  // mov	byte ptr [rdx + r9 + 3], al
	ADDQ $0x4, R9                  // <--                                  // add	r9, 4
	CMPQ R8, R9                    // <--                                  // cmp	r8, r9
	JNE  LBB0_17                   // <--                                  // jne	.LBB0_17

LBB0_18:
	NOP // (skipped)                            // mov	rsp, rbp
	NOP // (skipped)                            // pop	rbp

LBB0_19:
	VZEROUPPER // <--                                  // vzeroupper
	RET        // <--                                  // ret

LBB0_3:
	MOVQ DX, AX     // <--                                  // mov	rax, rdx
	SUBQ DI, AX     // <--                                  // sub	rax, rdi
	XORL R9, R9     // <--                                  // xor	r9d, r9d
	CMPQ AX, $0x100 // <--                                  // cmp	rax, 256
	JB   LBB0_14    // <--                                  // jb	.LBB0_14
	MOVQ DX, AX     // <--                                  // mov	rax, rdx
	SUBQ SI, AX     // <--                                  // sub	rax, rsi
	CMPQ AX, $0x100 // <--                                  // cmp	rax, 256
	JB   LBB0_14    // <--                                  // jb	.LBB0_14
	CMPL R8, $0x100 // <--                                  // cmp	r8d, 256
	JAE  LBB0_7     // <--                                  // jae	.LBB0_7
	XORL R9, R9     // <--                                  // xor	r9d, r9d
	JMP  LBB0_11    // <--                                  // jmp	.LBB0_11

LBB0_7:
	WORD         $0xb60f; BYTE $0xc1 // MOVZX CL, AX                         // movzx	eax, cl
	MOVQ         R8, R9              // <--                                  // mov	r9, r8
	SUBQ         AX, R9              // <--                                  // sub	r9, rax
	XORL         R10, R10            // <--                                  // xor	r10d, r10d
	VPBROADCASTW LCPI0_1<>(SB), Y0   // <--                                  // vpbroadcastw	ymm0, word ptr [rip + .LCPI0_1]

LBB0_8:
	LONG $0x6f7ea1c4; WORD $0x170c             // VMOVDQU 0(DI)(R10*1), Y1             // vmovdqu	ymm1, ymmword ptr [rdi + r10]
	LONG $0x6f7ea1c4; WORD $0x1754; BYTE $0x20 // VMOVDQU 0x20(DI)(R10*1), Y2          // vmovdqu	ymm2, ymmword ptr [rdi + r10 + 32]
	LONG $0x6f7ea1c4; WORD $0x175c; BYTE $0x40 // VMOVDQU 0x40(DI)(R10*1), Y3          // vmovdqu	ymm3, ymmword ptr [rdi + r10 + 64]
	LONG $0x6f7ea1c4; WORD $0x1764; BYTE $0x60 // VMOVDQU 0x60(DI)(R10*1), Y4          // vmovdqu	ymm4, ymmword ptr [rdi + r10 + 96]
	LONG $0xe968f5c5                           // VPUNPCKHBW Y1, Y1, Y5                // vpunpckhbw	ymm5, ymm1, ymm1
	LONG $0x6f7ea1c4; WORD $0x1634             // VMOVDQU 0(SI)(R10*1), Y6             // vmovdqu	ymm6, ymmword ptr [rsi + r10]
	LONG $0x6f7ea1c4; WORD $0x167c; BYTE $0x20 // VMOVDQU 0x20(SI)(R10*1), Y7          // vmovdqu	ymm7, ymmword ptr [rsi + r10 + 32]
	LONG $0x6f7e21c4; WORD $0x1644; BYTE $0x40 // VMOVDQU 0x40(SI)(R10*1), Y8          // vmovdqu	ymm8, ymmword ptr [rsi + r10 + 64]
	LONG $0x6f7e21c4; WORD $0x164c; BYTE $0x60 // VMOVDQU 0x60(SI)(R10*1), Y9          // vmovdqu	ymm9, ymmword ptr [rsi + r10 + 96]
	LONG $0xd6684dc5                           // VPUNPCKHBW Y6, Y6, Y10               // vpunpckhbw	ymm10, ymm6, ymm6
	LONG $0xedd5adc5                           // VPMULLW Y5, Y10, Y5                  // vpmullw	ymm5, ymm10, ymm5
	LONG $0xe8dbd5c5                           // VPAND Y0, Y5, Y5                     // vpand	ymm5, ymm5, ymm0
	LONG $0xc960f5c5                           // VPUNPCKLBW Y1, Y1, Y1                // vpunpcklbw	ymm1, ymm1, ymm1
	LONG $0xf660cdc5                           // VPUNPCKLBW Y6, Y6, Y6                // vpunpcklbw	ymm6, ymm6, ymm6
	LONG $0xc9d5cdc5                           // VPMULLW Y1, Y6, Y1                   // vpmullw	ymm1, ymm6, ymm1
	LONG $0xc8dbf5c5                           // VPAND Y0, Y1, Y1                     // vpand	ymm1, ymm1, ymm0
	LONG $0xcd67f5c5                           // VPACKUSWB Y5, Y1, Y1                 // vpackuswb	ymm1, ymm1, ymm5
	LONG $0xea68edc5                           // VPUNPCKHBW Y2, Y2, Y5                // vpunpckhbw	ymm5, ymm2, ymm2
	LONG $0xf768c5c5                           // VPUNPCKHBW Y7, Y7, Y6                // vpunpckhbw	ymm6, ymm7, ymm7
	LONG $0xedd5cdc5                           // VPMULLW Y5, Y6, Y5                   // vpmullw	ymm5, ymm6, ymm5
	LONG $0xe8dbd5c5                           // VPAND Y0, Y5, Y5                     // vpand	ymm5, ymm5, ymm0
	LONG $0xd260edc5                           // VPUNPCKLBW Y2, Y2, Y2                // vpunpcklbw	ymm2, ymm2, ymm2
	LONG $0xf760c5c5                           // VPUNPCKLBW Y7, Y7, Y6                // vpunpcklbw	ymm6, ymm7, ymm7
	LONG $0xd2d5cdc5                           // VPMULLW Y2, Y6, Y2                   // vpmullw	ymm2, ymm6, ymm2
	LONG $0xd0dbedc5                           // VPAND Y0, Y2, Y2                     // vpand	ymm2, ymm2, ymm0
	LONG $0xd567edc5                           // VPACKUSWB Y5, Y2, Y2                 // vpackuswb	ymm2, ymm2, ymm5
	LONG $0xeb68e5c5                           // VPUNPCKHBW Y3, Y3, Y5                // vpunpckhbw	ymm5, ymm3, ymm3
	LONG $0x683dc1c4; BYTE $0xf0               // VPUNPCKHBW Y8, Y8, Y6                // vpunpckhbw	ymm6, ymm8, ymm8
	LONG $0xedd5cdc5                           // VPMULLW Y5, Y6, Y5                   // vpmullw	ymm5, ymm6, ymm5
	LONG $0xe8dbd5c5                           // VPAND Y0, Y5, Y5                     // vpand	ymm5, ymm5, ymm0
	LONG $0xdb60e5c5                           // VPUNPCKLBW Y3, Y3, Y3                // vpunpcklbw	ymm3, ymm3, ymm3
	LONG $0x603dc1c4; BYTE $0xf0               // VPUNPCKLBW Y8, Y8, Y6                // vpunpcklbw	ymm6, ymm8, ymm8
	LONG $0xdbd5cdc5                           // VPMULLW Y3, Y6, Y3                   // vpmullw	ymm3, ymm6, ymm3
	LONG $0xd8dbe5c5                           // VPAND Y0, Y3, Y3                     // vpand	ymm3, ymm3, ymm0
	LONG $0xdd67e5c5                           // VPACKUSWB Y5, Y3, Y3                 // vpackuswb	ymm3, ymm3, ymm5
	LONG $0xec68ddc5                           // VPUNPCKHBW Y4, Y4, Y5                // vpunpckhbw	ymm5, ymm4, ymm4
	LONG $0x6835c1c4; BYTE $0xf1               // VPUNPCKHBW Y9, Y9, Y6                // vpunpckhbw	ymm6, ymm9, ymm9
	LONG $0xedd5cdc5                           // VPMULLW Y5, Y6, Y5                   // vpmullw	ymm5, ymm6, ymm5
	LONG $0xe8dbd5c5                           // VPAND Y0, Y5, Y5                     // vpand	ymm5, ymm5, ymm0
	LONG $0xe460ddc5                           // VPUNPCKLBW Y4, Y4, Y4                // vpunpcklbw	ymm4, ymm4, ymm4
	LONG $0x6035c1c4; BYTE $0xf1               // VPUNPCKLBW Y9, Y9, Y6                // vpunpcklbw	ymm6, ymm9, ymm9
	LONG $0xe4d5cdc5                           // VPMULLW Y4, Y6, Y4                   // vpmullw	ymm4, ymm6, ymm4
	LONG $0xe0dbddc5                           // VPAND Y0, Y4, Y4                     // vpand	ymm4, ymm4, ymm0
	LONG $0xe567ddc5                           // VPACKUSWB Y5, Y4, Y4                 // vpackuswb	ymm4, ymm4, ymm5
	QUAD $0x008017ac6f7ea1c4; WORD $0x0000     // VMOVDQU 0x80(DI)(R10*1), Y5          // vmovdqu	ymm5, ymmword ptr [rdi + r10 + 128]
	LONG $0xf568d5c5                           // VPUNPCKHBW Y5, Y5, Y6                // vpunpckhbw	ymm6, ymm5, ymm5
	QUAD $0x008016bc6f7ea1c4; WORD $0x0000     // VMOVDQU 0x80(SI)(R10*1), Y7          // vmovdqu	ymm7, ymmword ptr [rsi + r10 + 128]
	LONG $0xc76845c5                           // VPUNPCKHBW Y7, Y7, Y8                // vpunpckhbw	ymm8, ymm7, ymm7
	LONG $0xf6d5bdc5                           // VPMULLW Y6, Y8, Y6                   // vpmullw	ymm6, ymm8, ymm6
	LONG $0xf0dbcdc5                           // VPAND Y0, Y6, Y6                     // vpand	ymm6, ymm6, ymm0
	LONG $0xed60d5c5                           // VPUNPCKLBW Y5, Y5, Y5                // vpunpcklbw	ymm5, ymm5, ymm5
	LONG $0xff60c5c5                           // VPUNPCKLBW Y7, Y7, Y7                // vpunpcklbw	ymm7, ymm7, ymm7
	LONG $0xedd5c5c5                           // VPMULLW Y5, Y7, Y5                   // vpmullw	ymm5, ymm7, ymm5
	LONG $0xe8dbd5c5                           // VPAND Y0, Y5, Y5                     // vpand	ymm5, ymm5, ymm0
	LONG $0xee67d5c5                           // VPACKUSWB Y6, Y5, Y5                 // vpackuswb	ymm5, ymm5, ymm6
	QUAD $0x00a017b46f7ea1c4; WORD $0x0000     // VMOVDQU 0xa0(DI)(R10*1), Y6          // vmovdqu	ymm6, ymmword ptr [rdi + r10 + 160]
	LONG $0xfe68cdc5                           // VPUNPCKHBW Y6, Y6, Y7                // vpunpckhbw	ymm7, ymm6, ymm6
	QUAD $0x00a016846f7e21c4; WORD $0x0000     // VMOVDQU 0xa0(SI)(R10*1), Y8          // vmovdqu	ymm8, ymmword ptr [rsi + r10 + 160]
	LONG $0x683d41c4; BYTE $0xc8               // VPUNPCKHBW Y8, Y8, Y9                // vpunpckhbw	ymm9, ymm8, ymm8
	LONG $0xffd5b5c5                           // VPMULLW Y7, Y9, Y7                   // vpmullw	ymm7, ymm9, ymm7
	LONG $0xf8dbc5c5                           // VPAND Y0, Y7, Y7                     // vpand	ymm7, ymm7, ymm0
	LONG $0xf660cdc5                           // VPUNPCKLBW Y6, Y6, Y6                // vpunpcklbw	ymm6, ymm6, ymm6
	LONG $0x603d41c4; BYTE $0xc0               // VPUNPCKLBW Y8, Y8, Y8                // vpunpcklbw	ymm8, ymm8, ymm8
	LONG $0xf6d5bdc5                           // VPMULLW Y6, Y8, Y6                   // vpmullw	ymm6, ymm8, ymm6
	LONG $0xf0dbcdc5                           // VPAND Y0, Y6, Y6                     // vpand	ymm6, ymm6, ymm0
	LONG $0xf767cdc5                           // VPACKUSWB Y7, Y6, Y6                 // vpackuswb	ymm6, ymm6, ymm7
	QUAD $0x00c017bc6f7ea1c4; WORD $0x0000     // VMOVDQU 0xc0(DI)(R10*1), Y7          // vmovdqu	ymm7, ymmword ptr [rdi + r10 + 192]
	LONG $0xc76845c5                           // VPUNPCKHBW Y7, Y7, Y8                // vpunpckhbw	ymm8, ymm7, ymm7
	QUAD $0x00c0168c6f7e21c4; WORD $0x0000     // VMOVDQU 0xc0(SI)(R10*1), Y9          // vmovdqu	ymm9, ymmword ptr [rsi + r10 + 192]
	LONG $0x683541c4; BYTE $0xd1               // VPUNPCKHBW Y9, Y9, Y10               // vpunpckhbw	ymm10, ymm9, ymm9
	LONG $0xd52d41c4; BYTE $0xc0               // VPMULLW Y8, Y10, Y8                  // vpmullw	ymm8, ymm10, ymm8
	LONG $0xc0db3dc5                           // VPAND Y0, Y8, Y8                     // vpand	ymm8, ymm8, ymm0
	LONG $0xff60c5c5                           // VPUNPCKLBW Y7, Y7, Y7                // vpunpcklbw	ymm7, ymm7, ymm7
	LONG $0x603541c4; BYTE $0xc9               // VPUNPCKLBW Y9, Y9, Y9                // vpunpcklbw	ymm9, ymm9, ymm9
	LONG $0xffd5b5c5                           // VPMULLW Y7, Y9, Y7                   // vpmullw	ymm7, ymm9, ymm7
	LONG $0xf8dbc5c5                           // VPAND Y0, Y7, Y7                     // vpand	ymm7, ymm7, ymm0
	LONG $0x6745c1c4; BYTE $0xf8               // VPACKUSWB Y8, Y7, Y7                 // vpackuswb	ymm7, ymm7, ymm8
	QUAD $0x00e017846f7e21c4; WORD $0x0000     // VMOVDQU 0xe0(DI)(R10*1), Y8          // vmovdqu	ymm8, ymmword ptr [rdi + r10 + 224]
	LONG $0x683d41c4; BYTE $0xc8               // VPUNPCKHBW Y8, Y8, Y9                // vpunpckhbw	ymm9, ymm8, ymm8
	QUAD $0x00e016946f7e21c4; WORD $0x0000     // VMOVDQU 0xe0(SI)(R10*1), Y10         // vmovdqu	ymm10, ymmword ptr [rsi + r10 + 224]
	LONG $0x682d41c4; BYTE $0xda               // VPUNPCKHBW Y10, Y10, Y11             // vpunpckhbw	ymm11, ymm10, ymm10
	LONG $0xd52541c4; BYTE $0xc9               // VPMULLW Y9, Y11, Y9                  // vpmullw	ymm9, ymm11, ymm9
	LONG $0xc8db35c5                           // VPAND Y0, Y9, Y9                     // vpand	ymm9, ymm9, ymm0
	LONG $0x603d41c4; BYTE $0xc0               // VPUNPCKLBW Y8, Y8, Y8                // vpunpcklbw	ymm8, ymm8, ymm8
	LONG $0x602d41c4; BYTE $0xd2               // VPUNPCKLBW Y10, Y10, Y10             // vpunpcklbw	ymm10, ymm10, ymm10
	LONG $0xd52d41c4; BYTE $0xc0               // VPMULLW Y8, Y10, Y8                  // vpmullw	ymm8, ymm10, ymm8
	LONG $0xc0db3dc5                           // VPAND Y0, Y8, Y8                     // vpand	ymm8, ymm8, ymm0
	LONG $0x673d41c4; BYTE $0xc1               // VPACKUSWB Y9, Y8, Y8                 // vpackuswb	ymm8, ymm8, ymm9
	LONG $0x7f7ea1c4; WORD $0x1254; BYTE $0x20 // VMOVDQU Y2, 0x20(DX)(R10*1)          // vmovdqu	ymmword ptr [rdx + r10 + 32], ymm2
	LONG $0x7f7ea1c4; WORD $0x120c             // VMOVDQU Y1, 0(DX)(R10*1)             // vmovdqu	ymmword ptr [rdx + r10], ymm1
	LONG $0x7f7ea1c4; WORD $0x1264; BYTE $0x60 // VMOVDQU Y4, 0x60(DX)(R10*1)          // vmovdqu	ymmword ptr [rdx + r10 + 96], ymm4
	LONG $0x7f7ea1c4; WORD $0x125c; BYTE $0x40 // VMOVDQU Y3, 0x40(DX)(R10*1)          // vmovdqu	ymmword ptr [rdx + r10 + 64], ymm3
	QUAD $0x00a012b47f7ea1c4; WORD $0x0000     // VMOVDQU Y6, 0xa0(DX)(R10*1)          // vmovdqu	ymmword ptr [rdx + r10 + 160], ymm6
	QUAD $0x008012ac7f7ea1c4; WORD $0x0000     // VMOVDQU Y5, 0x80(DX)(R10*1)          // vmovdqu	ymmword ptr [rdx + r10 + 128], ymm5
	QUAD $0x00e012847f7e21c4; WORD $0x0000     // VMOVDQU Y8, 0xe0(DX)(R10*1)          // vmovdqu	ymmword ptr [rdx + r10 + 224], ymm8
	QUAD $0x00c012bc7f7ea1c4; WORD $0x0000     // VMOVDQU Y7, 0xc0(DX)(R10*1)          // vmovdqu	ymmword ptr [rdx + r10 + 192], ymm7
	ADDQ $0x100, R10                           // <--                                  // add	r10, 256
	CMPQ R9, R10                               // <--                                  // cmp	r9, r10
	JNE  LBB0_8                                // <--                                  // jne	.LBB0_8
	WORD $0x8548; BYTE $0xc0                   // TESTQ AX, AX                         // test	rax, rax
	JE   LBB0_18                               // <--                                  // je	.LBB0_18
	CMPL AX, $0x20                             // <--                                  // cmp	eax, 32
	JB   LBB0_14                               // <--                                  // jb	.LBB0_14

LBB0_11:
	MOVQ         R9, AX              // <--                                  // mov	rax, r9
	WORD         $0x8941; BYTE $0xca // MOVL CX, R10                         // mov	r10d, ecx
	LONG         $0x1fe28341         // ANDL $0x1f, R10                      // and	r10d, 31
	MOVQ         R8, R9              // <--                                  // mov	r9, r8
	SUBQ         R10, R9             // <--                                  // sub	r9, r10
	VPBROADCASTW LCPI0_1<>(SB), Y0   // <--                                  // vpbroadcastw	ymm0, word ptr [rip + .LCPI0_1]

LBB0_12:
	LONG $0x0c6ffec5; BYTE $0x07 // VMOVDQU 0(DI)(AX*1), Y1              // vmovdqu	ymm1, ymmword ptr [rdi + rax]
	LONG $0x146ffec5; BYTE $0x06 // VMOVDQU 0(SI)(AX*1), Y2              // vmovdqu	ymm2, ymmword ptr [rsi + rax]
	LONG $0xd968f5c5             // VPUNPCKHBW Y1, Y1, Y3                // vpunpckhbw	ymm3, ymm1, ymm1
	LONG $0xe268edc5             // VPUNPCKHBW Y2, Y2, Y4                // vpunpckhbw	ymm4, ymm2, ymm2
	LONG $0xdbd5ddc5             // VPMULLW Y3, Y4, Y3                   // vpmullw	ymm3, ymm4, ymm3
	LONG $0xd8dbe5c5             // VPAND Y0, Y3, Y3                     // vpand	ymm3, ymm3, ymm0
	LONG $0xc960f5c5             // VPUNPCKLBW Y1, Y1, Y1                // vpunpcklbw	ymm1, ymm1, ymm1
	LONG $0xd260edc5             // VPUNPCKLBW Y2, Y2, Y2                // vpunpcklbw	ymm2, ymm2, ymm2
	LONG $0xc9d5edc5             // VPMULLW Y1, Y2, Y1                   // vpmullw	ymm1, ymm2, ymm1
	LONG $0xc8dbf5c5             // VPAND Y0, Y1, Y1                     // vpand	ymm1, ymm1, ymm0
	LONG $0xcb67f5c5             // VPACKUSWB Y3, Y1, Y1                 // vpackuswb	ymm1, ymm1, ymm3
	LONG $0x0c7ffec5; BYTE $0x02 // VMOVDQU Y1, 0(DX)(AX*1)              // vmovdqu	ymmword ptr [rdx + rax], ymm1
	ADDQ $0x20, AX               // <--                                  // add	rax, 32
	CMPQ R9, AX                  // <--                                  // cmp	r9, rax
	JNE  LBB0_12                 // <--                                  // jne	.LBB0_12
	WORD $0x854d; BYTE $0xd2     // TESTQ R10, R10                       // test	r10, r10
	JNE  LBB0_14                 // <--                                  // jne	.LBB0_14
	JMP  LBB0_18                 // <--                                  // jmp	.LBB0_18
