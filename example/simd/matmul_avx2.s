//go:build !noasm && amd64
// Code generated by gocc devel -- DO NOT EDIT.
//
// Source file         : matmul_avx2.c
// Clang version       : Apple clang version 16.0.0 (clang-1600.0.26.3)
// Target architecture : amd64
// Compiler options    : -mavx2 -mfma

#include "textflag.h"

TEXT ·f32_axpy(SB), NOSPLIT, $0-28
	MOVQ  x+0(FP), DI
	MOVQ  y+8(FP), SI
	MOVQ  size+16(FP), DX
	MOVSS alpha+24(FP), X0
	NOP                           // (skipped)                            // push	rbp
	NOP                           // (skipped)                            // mov	rbp, rsp
	NOP                           // (skipped)                            // and	rsp, -8
	CMPQ  DX, $0x8                // <--                                  // cmp	rdx, 8
	JB    LBB0_5                  // <--                                  // jb	.LBB0_5
	LONG  $0x187de2c4; BYTE $0xc8 // VBROADCASTSS X0, Y1                  // vbroadcastss	ymm1, xmm0
	LEAQ  -0x8(DX), CX            // <--                                  // lea	rcx, [rdx - 8]
	MOVQ  CX, AX                  // <--                                  // mov	rax, rcx
	SHRQ  $0x3, AX                // <--                                  // shr	rax, 3
	INCQ  AX                      // <--                                  // inc	rax
	CMPQ  CX, $0x8                // <--                                  // cmp	rcx, 8
	JAE   LBB0_12                 // <--                                  // jae	.LBB0_12
	XORL  CX, CX                  // <--                                  // xor	ecx, ecx
	JMP   LBB0_3                  // <--                                  // jmp	.LBB0_3

LBB0_12:
	MOVQ AX, R8    // <--                                  // mov	r8, rax
	ANDQ $-0x2, R8 // <--                                  // and	r8, -2
	XORL CX, CX    // <--                                  // xor	ecx, ecx

LBB0_13:
	LONG $0x1410fcc5; BYTE $0x8f               // VMOVUPS 0(DI)(CX*4), Y2              // vmovups	ymm2, ymmword ptr [rdi + 4*rcx]
	LONG $0xa875e2c4; WORD $0x8e14             // VFMADD213PS 0(SI)(CX*4), Y1, Y2      // vfmadd213ps	ymm2, ymm1, ymmword ptr [rsi + 4*rcx]
	LONG $0x1411fcc5; BYTE $0x8e               // VMOVUPS Y2, 0(SI)(CX*4)              // vmovups	ymmword ptr [rsi + 4*rcx], ymm2
	LONG $0x5410fcc5; WORD $0x208f             // VMOVUPS 0x20(DI)(CX*4), Y2           // vmovups	ymm2, ymmword ptr [rdi + 4*rcx + 32]
	LONG $0xa875e2c4; WORD $0x8e54; BYTE $0x20 // VFMADD213PS 0x20(SI)(CX*4), Y1, Y2   // vfmadd213ps	ymm2, ymm1, ymmword ptr [rsi + 4*rcx + 32]
	LONG $0x5411fcc5; WORD $0x208e             // VMOVUPS Y2, 0x20(SI)(CX*4)           // vmovups	ymmword ptr [rsi + 4*rcx + 32], ymm2
	ADDQ $0x10, CX                             // <--                                  // add	rcx, 16
	ADDQ $-0x2, R8                             // <--                                  // add	r8, -2
	JNE  LBB0_13                               // <--                                  // jne	.LBB0_13

LBB0_3:
	WORD $0x01a8                   // TESTL $0x1, AL                       // test	al, 1
	JE   LBB0_5                    // <--                                  // je	.LBB0_5
	LONG $0x1410fcc5; BYTE $0x8f   // VMOVUPS 0(DI)(CX*4), Y2              // vmovups	ymm2, ymmword ptr [rdi + 4*rcx]
	LONG $0xa86de2c4; WORD $0x8e0c // VFMADD213PS 0(SI)(CX*4), Y2, Y1      // vfmadd213ps	ymm1, ymm2, ymmword ptr [rsi + 4*rcx]
	LONG $0x0c11fcc5; BYTE $0x8e   // VMOVUPS Y1, 0(SI)(CX*4)              // vmovups	ymmword ptr [rsi + 4*rcx], ymm1

LBB0_5:
	WORD $0xc2f6; BYTE $0x07       // TESTL $0x7, DL                       // test	dl, 7
	JE   LBB0_11                   // <--                                  // je	.LBB0_11
	MOVQ DX, AX                    // <--                                  // mov	rax, rdx
	ANDQ $-0x8, AX                 // <--                                  // and	rax, -8
	CMPQ AX, DX                    // <--                                  // cmp	rax, rdx
	JAE  LBB0_11                   // <--                                  // jae	.LBB0_11
	MOVQ AX, CX                    // <--                                  // mov	rcx, rax
	NOTQ CX                        // <--                                  // not	rcx
	WORD $0xc2f6; BYTE $0x01       // TESTL $0x1, DL                       // test	dl, 1
	JE   LBB0_9                    // <--                                  // je	.LBB0_9
	LONG $0x0c10fac5; BYTE $0x87   // VMOVSS 0(DI)(AX*4), X1               // vmovss	xmm1, dword ptr [rdi + 4*rax]
	LONG $0xa979e2c4; WORD $0x860c // VFMADD213SS 0(SI)(AX*4), X0, X1      // vfmadd213ss	xmm1, xmm0, dword ptr [rsi + 4*rax]
	LONG $0x0c11fac5; BYTE $0x86   // VMOVSS X1, 0(SI)(AX*4)               // vmovss	dword ptr [rsi + 4*rax], xmm1
	ORQ  $0x1, AX                  // <--                                  // or	rax, 1

LBB0_9:
	ADDQ DX, CX  // <--                                  // add	rcx, rdx
	JE   LBB0_11 // <--                                  // je	.LBB0_11

LBB0_10:
	LONG $0x0c10fac5; BYTE $0x87               // VMOVSS 0(DI)(AX*4), X1               // vmovss	xmm1, dword ptr [rdi + 4*rax]
	LONG $0xa979e2c4; WORD $0x860c             // VFMADD213SS 0(SI)(AX*4), X0, X1      // vfmadd213ss	xmm1, xmm0, dword ptr [rsi + 4*rax]
	LONG $0x0c11fac5; BYTE $0x86               // VMOVSS X1, 0(SI)(AX*4)               // vmovss	dword ptr [rsi + 4*rax], xmm1
	LONG $0x4c10fac5; WORD $0x0487             // VMOVSS 0x4(DI)(AX*4), X1             // vmovss	xmm1, dword ptr [rdi + 4*rax + 4]
	LONG $0xa979e2c4; WORD $0x864c; BYTE $0x04 // VFMADD213SS 0x4(SI)(AX*4), X0, X1    // vfmadd213ss	xmm1, xmm0, dword ptr [rsi + 4*rax + 4]
	LONG $0x4c11fac5; WORD $0x0486             // VMOVSS X1, 0x4(SI)(AX*4)             // vmovss	dword ptr [rsi + 4*rax + 4], xmm1
	ADDQ $0x2, AX                              // <--                                  // add	rax, 2
	CMPQ AX, DX                                // <--                                  // cmp	rax, rdx
	JB   LBB0_10                               // <--                                  // jb	.LBB0_10

LBB0_11:
	NOP        // (skipped)                            // mov	rsp, rbp
	NOP        // (skipped)                            // pop	rbp
	VZEROUPPER // <--                                  // vzeroupper
	RET        // <--                                  // ret

TEXT ·f32_matmul(SB), 0, $464-32
	MOVQ  dst+0(FP), DI
	MOVQ  m+8(FP), SI
	MOVQ  n+16(FP), DX
	MOVQ  dims+24(FP), CX
	NOP                           // (skipped)                            // push	rbp
	NOP                           // (skipped)                            // mov	rbp, rsp
	MOVQ  R15, 424(SP)            // <--                                  // push	r15
	MOVQ  R14, 432(SP)            // <--                                  // push	r14
	MOVQ  R13, 440(SP)            // <--                                  // push	r13
	MOVQ  R12, 448(SP)            // <--                                  // push	r12
	MOVQ  BX, 456(SP)             // <--                                  // push	rbx
	ANDQ  $-0x8, SP               // <--                                  // and	rsp, -8
	NOP                           // (skipped)                            // sub	rsp, 424
	MOVQ  DX, 0x8(SP)             // <--                                  // mov	qword ptr [rsp + 8], rdx
	MOVQ  CX, AX                  // <--                                  // mov	rax, rcx
	ANDQ  $0xffff, AX             // <--                                  // and	rax, 65535
	MOVQ  AX, 0x10(SP)            // <--                                  // mov	qword ptr [rsp + 16], rax
	JE    LBB1_27                 // <--                                  // je	.LBB1_27
	MOVQ  CX, R9                  // <--                                  // mov	r9, rcx
	SHRQ  $0x30, R9               // <--                                  // shr	r9, 48
	JE    LBB1_27                 // <--                                  // je	.LBB1_27
	MOVQ  CX, AX                  // <--                                  // mov	rax, rcx
	SHRQ  $0x10, AX               // <--                                  // shr	rax, 16
	LONG  $0xc0b70f44             // MOVZX AX, R8                         // movzx	r8d, ax
	LONG  $0x00fff825; BYTE $0x00 // ANDL $0xfff8, AX                     // and	eax, 65528
	CMPQ  R9, $0x1                // <--                                  // cmp	r9, 1
	MOVQ  R9, DX                  // <--                                  // mov	rdx, r9
	ADCQ  $0x0, DX                // <--                                  // adc	rdx, 0
	MOVQ  R8, R14                 // <--                                  // mov	r14, r8
	SUBQ  AX, R14                 // <--                                  // sub	r14, rax
	MOVQ  R8, R10                 // <--                                  // mov	r10, r8
	SUBQ  AX, R10                 // <--                                  // sub	r10, rax
	MOVQ  DX, 0x18(SP)            // <--                                  // mov	qword ptr [rsp + 24], rdx
	JBE   LBB1_3                  // <--                                  // jbe	.LBB1_3
	CMPQ  R10, $0x20              // <--                                  // cmp	r10, 32
	MOVQ  R9, 0x20(SP)            // <--                                  // mov	qword ptr [rsp + 32], r9
	MOVQ  R8, 0x30(SP)            // <--                                  // mov	qword ptr [rsp + 48], r8
	MOVQ  DI, 0x40(SP)            // <--                                  // mov	qword ptr [rsp + 64], rdi
	JAE   LBB1_7                  // <--                                  // jae	.LBB1_7
	MOVQ  AX, R15                 // <--                                  // mov	r15, rax
	WORD  $0xe9c1; BYTE $0x13     // SHRL $0x13, CX                       // shr	ecx, 19
	IMULQ R9, CX                  // <--                                  // imul	rcx, r9
	SHLQ  $0x5, CX                // <--                                  // shl	rcx, 5
	ADDQ  CX, 0x8(SP)             // <--                                  // add	qword ptr [rsp + 8], rcx
	LEAQ  0(R9*4), AX             // <--                                  // lea	rax, [4*r9]
	LEAQ  0(R8*4), CX             // <--                                  // lea	rcx, [4*r8]
	XORL  DX, DX                  // <--                                  // xor	edx, edx
	MOVQ  0x18(SP), BX            // <--                                  // mov	rbx, qword ptr [rsp + 24]
	MOVQ  0x30(SP), R12           // <--                                  // mov	r12, qword ptr [rsp + 48]

LBB1_16:
	MOVQ  DX, R14      // <--                                  // mov	r14, rdx
	IMULQ R9, R14      // <--                                  // imul	r14, r9
	MOVQ  0x8(SP), R11 // <--                                  // mov	r11, qword ptr [rsp + 8]
	XORL  R8, R8       // <--                                  // xor	r8d, r8d
	MOVQ  R15, DI      // <--                                  // mov	rdi, r15

LBB1_17:
	LONG $0xc057f8c5 // VXORPS X0, X0, X0                    // vxorps	xmm0, xmm0, xmm0
	MOVQ R11, R9     // <--                                  // mov	r9, r11
	MOVQ DI, R10     // <--                                  // mov	r10, rdi

LBB1_18:
	LONG $0x107ac1c4; BYTE $0x09   // VMOVSS 0(R9), X1                     // vmovss	xmm1, dword ptr [r9]
	LONG $0xb971a2c4; WORD $0x9604 // VFMADD231SS 0(SI)(R10*4), X1, X0     // vfmadd231ss	xmm0, xmm1, dword ptr [rsi + 4*r10]
	INCQ R10                       // <--                                  // inc	r10
	ADDQ AX, R9                    // <--                                  // add	r9, rax
	CMPQ R12, R10                  // <--                                  // cmp	r12, r10
	JNE  LBB1_18                   // <--                                  // jne	.LBB1_18
	LEAQ 0(R8)(R14*1), R9          // <--                                  // lea	r9, [r8 + r14]
	MOVQ 0x40(SP), R10             // <--                                  // mov	r10, qword ptr [rsp + 64]
	LONG $0x117a81c4; WORD $0x8a04 // VMOVSS X0, 0(R10)(R9*4)              // vmovss	dword ptr [r10 + 4*r9], xmm0
	INCQ R8                        // <--                                  // inc	r8
	ADDQ $0x4, R11                 // <--                                  // add	r11, 4
	CMPQ R8, BX                    // <--                                  // cmp	r8, rbx
	JNE  LBB1_17                   // <--                                  // jne	.LBB1_17
	INCQ DX                        // <--                                  // inc	rdx
	ADDQ CX, SI                    // <--                                  // add	rsi, rcx
	CMPQ DX, 0x10(SP)              // <--                                  // cmp	rdx, qword ptr [rsp + 16]
	MOVQ 0x20(SP), R9              // <--                                  // mov	r9, qword ptr [rsp + 32]
	JNE  LBB1_16                   // <--                                  // jne	.LBB1_16

LBB1_27:
	NOP               // (skipped)                            // lea	rsp, [rbp - 40]
	MOVQ 456(SP), BX  // <--                                  // pop	rbx
	MOVQ 448(SP), R12 // <--                                  // pop	r12
	MOVQ 440(SP), R13 // <--                                  // pop	r13
	MOVQ 432(SP), R14 // <--                                  // pop	r14
	MOVQ 424(SP), R15 // <--                                  // pop	r15
	NOP               // (skipped)                            // pop	rbp
	VZEROUPPER        // <--                                  // vzeroupper
	RET               // <--                                  // ret

LBB1_3:
	WORD $0xd089                   // MOVL DX, AX                          // mov	eax, edx
	WORD $0xe083; BYTE $0x03       // ANDL $0x3, AX                        // and	eax, 3
	WORD $0xd189                   // MOVL DX, CX                          // mov	ecx, edx
	LONG $0xfffce181; WORD $0x0000 // ANDL $0xfffc, CX                     // and	ecx, 65532
	LEAQ 0xc(DI), DX               // <--                                  // lea	rdx, [rdi + 12]
	SHLQ $0x2, R9                  // <--                                  // shl	r9, 2
	XORL SI, SI                    // <--                                  // xor	esi, esi
	LONG $0xc057f8c5               // VXORPS X0, X0, X0                    // vxorps	xmm0, xmm0, xmm0
	MOVQ R9, R10                   // <--                                  // mov	r10, r9
	JMP  LBB1_4                    // <--                                  // jmp	.LBB1_4

LBB1_26:
	INCQ SI           // <--                                  // inc	rsi
	MOVQ R10, R8      // <--                                  // mov	r8, r10
	ADDQ R10, DX      // <--                                  // add	rdx, r10
	ADDQ R10, DI      // <--                                  // add	rdi, r10
	CMPQ SI, 0x10(SP) // <--                                  // cmp	rsi, qword ptr [rsp + 16]
	JE   LBB1_27      // <--                                  // je	.LBB1_27

LBB1_4:
	CMPQ 0x18(SP), $0x4 // <--                                  // cmp	qword ptr [rsp + 24], 4
	JAE  LBB1_21        // <--                                  // jae	.LBB1_21
	XORL R8, R8         // <--                                  // xor	r8d, r8d
	JMP  LBB1_23        // <--                                  // jmp	.LBB1_23

LBB1_21:
	XORL R8, R8 // <--                                  // xor	r8d, r8d

LBB1_22:
	LONG $0x1178a1c4; WORD $0x8244; BYTE $0xf4 // VMOVUPS X0, -0xc(DX)(R8*4)           // vmovups	xmmword ptr [rdx + 4*r8 - 12], xmm0
	ADDQ $0x4, R8                              // <--                                  // add	r8, 4
	CMPQ CX, R8                                // <--                                  // cmp	rcx, r8
	JNE  LBB1_22                               // <--                                  // jne	.LBB1_22

LBB1_23:
	WORD $0x8548; BYTE $0xc0 // TESTQ AX, AX                         // test	rax, rax
	JE   LBB1_26             // <--                                  // je	.LBB1_26
	LEAQ 0(DI)(R8*4), R9     // <--                                  // lea	r9, [rdi + 4*r8]
	XORL R8, R8              // <--                                  // xor	r8d, r8d

LBB1_25:
	QUAD $0x000000008104c743 // MOVL $0x0, 0(R9)(R8*4)               // mov	dword ptr [r9 + 4*r8], 0
	INCQ R8                  // <--                                  // inc	r8
	CMPQ AX, R8              // <--                                  // cmp	rax, r8
	JNE  LBB1_25             // <--                                  // jne	.LBB1_25
	JMP  LBB1_26             // <--                                  // jmp	.LBB1_26

LBB1_7:
	MOVQ  R10, 0xc0(SP)       // <--                                  // mov	qword ptr [rsp + 192], r10
	ANDQ  $-0x20, R14         // <--                                  // and	r14, -32
	WORD  $0xe9c1; BYTE $0x13 // SHRL $0x13, CX                       // shr	ecx, 19
	MOVQ  R9, DX              // <--                                  // mov	rdx, r9
	IMULQ CX, DX              // <--                                  // imul	rdx, rcx
	SHLQ  $0x5, DX            // <--                                  // shl	rdx, 5
	MOVQ  DX, 0x198(SP)       // <--                                  // mov	qword ptr [rsp + 408], rdx
	MOVQ  R9, DX              // <--                                  // mov	rdx, r9
	SHLQ  $0x7, DX            // <--                                  // shl	rdx, 7
	MOVQ  DX, 0x190(SP)       // <--                                  // mov	qword ptr [rsp + 400], rdx
	SHLQ  $0x5, CX            // <--                                  // shl	rcx, 5
	ADDQ  SI, CX              // <--                                  // add	rcx, rsi
	ADDQ  $0x60, CX           // <--                                  // add	rcx, 96
	MOVQ  CX, 0x28(SP)        // <--                                  // mov	qword ptr [rsp + 40], rcx
	LEAQ  0x1f(AX), CX        // <--                                  // lea	rcx, [rax + 31]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x188(SP)       // <--                                  // mov	qword ptr [rsp + 392], rcx
	LEAQ  0x1e(AX), CX        // <--                                  // lea	rcx, [rax + 30]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x180(SP)       // <--                                  // mov	qword ptr [rsp + 384], rcx
	LEAQ  0x1d(AX), CX        // <--                                  // lea	rcx, [rax + 29]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x178(SP)       // <--                                  // mov	qword ptr [rsp + 376], rcx
	LEAQ  0x1c(AX), CX        // <--                                  // lea	rcx, [rax + 28]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x170(SP)       // <--                                  // mov	qword ptr [rsp + 368], rcx
	LEAQ  0x1b(AX), CX        // <--                                  // lea	rcx, [rax + 27]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x168(SP)       // <--                                  // mov	qword ptr [rsp + 360], rcx
	LEAQ  0x1a(AX), CX        // <--                                  // lea	rcx, [rax + 26]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x160(SP)       // <--                                  // mov	qword ptr [rsp + 352], rcx
	LEAQ  0x19(AX), CX        // <--                                  // lea	rcx, [rax + 25]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x158(SP)       // <--                                  // mov	qword ptr [rsp + 344], rcx
	LEAQ  0x18(AX), CX        // <--                                  // lea	rcx, [rax + 24]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x150(SP)       // <--                                  // mov	qword ptr [rsp + 336], rcx
	LEAQ  0x17(AX), CX        // <--                                  // lea	rcx, [rax + 23]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x148(SP)       // <--                                  // mov	qword ptr [rsp + 328], rcx
	LEAQ  0x16(AX), CX        // <--                                  // lea	rcx, [rax + 22]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x140(SP)       // <--                                  // mov	qword ptr [rsp + 320], rcx
	LEAQ  0x15(AX), CX        // <--                                  // lea	rcx, [rax + 21]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x138(SP)       // <--                                  // mov	qword ptr [rsp + 312], rcx
	LEAQ  0x14(AX), CX        // <--                                  // lea	rcx, [rax + 20]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x130(SP)       // <--                                  // mov	qword ptr [rsp + 304], rcx
	LEAQ  0x13(AX), CX        // <--                                  // lea	rcx, [rax + 19]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x128(SP)       // <--                                  // mov	qword ptr [rsp + 296], rcx
	LEAQ  0x12(AX), CX        // <--                                  // lea	rcx, [rax + 18]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x120(SP)       // <--                                  // mov	qword ptr [rsp + 288], rcx
	LEAQ  0x11(AX), CX        // <--                                  // lea	rcx, [rax + 17]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x118(SP)       // <--                                  // mov	qword ptr [rsp + 280], rcx
	LEAQ  0x10(AX), CX        // <--                                  // lea	rcx, [rax + 16]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x110(SP)       // <--                                  // mov	qword ptr [rsp + 272], rcx
	LEAQ  0xf(AX), CX         // <--                                  // lea	rcx, [rax + 15]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x108(SP)       // <--                                  // mov	qword ptr [rsp + 264], rcx
	LEAQ  0xe(AX), CX         // <--                                  // lea	rcx, [rax + 14]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x100(SP)       // <--                                  // mov	qword ptr [rsp + 256], rcx
	LEAQ  0xd(AX), CX         // <--                                  // lea	rcx, [rax + 13]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0xf8(SP)        // <--                                  // mov	qword ptr [rsp + 248], rcx
	LEAQ  0xc(AX), CX         // <--                                  // lea	rcx, [rax + 12]
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0xf0(SP)        // <--                                  // mov	qword ptr [rsp + 240], rcx
	MOVQ  AX, CX              // <--                                  // mov	rcx, rax
	ADDQ  $0xb, AX            // <--                                  // add	rax, 11
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0xb8(SP)        // <--                                  // mov	qword ptr [rsp + 184], rax
	LEAQ  0xa(CX), AX         // <--                                  // lea	rax, [rcx + 10]
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0xb0(SP)        // <--                                  // mov	qword ptr [rsp + 176], rax
	LEAQ  0x9(CX), AX         // <--                                  // lea	rax, [rcx + 9]
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0xa8(SP)        // <--                                  // mov	qword ptr [rsp + 168], rax
	LEAQ  0x8(CX), AX         // <--                                  // lea	rax, [rcx + 8]
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0xa0(SP)        // <--                                  // mov	qword ptr [rsp + 160], rax
	LEAQ  0x7(CX), AX         // <--                                  // lea	rax, [rcx + 7]
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0x98(SP)        // <--                                  // mov	qword ptr [rsp + 152], rax
	MOVQ  R8, DI              // <--                                  // mov	rdi, r8
	LEAQ  0x6(CX), AX         // <--                                  // lea	rax, [rcx + 6]
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0x90(SP)        // <--                                  // mov	qword ptr [rsp + 144], rax
	LEAQ  0x5(CX), AX         // <--                                  // lea	rax, [rcx + 5]
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0x88(SP)        // <--                                  // mov	qword ptr [rsp + 136], rax
	LEAQ  0x4(CX), AX         // <--                                  // lea	rax, [rcx + 4]
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0x80(SP)        // <--                                  // mov	qword ptr [rsp + 128], rax
	LEAQ  0x3(CX), AX         // <--                                  // lea	rax, [rcx + 3]
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0x78(SP)        // <--                                  // mov	qword ptr [rsp + 120], rax
	LEAQ  0x2(CX), AX         // <--                                  // lea	rax, [rcx + 2]
	IMULQ R9, AX              // <--                                  // imul	rax, r9
	MOVQ  AX, 0x70(SP)        // <--                                  // mov	qword ptr [rsp + 112], rax
	MOVQ  R14, 0x38(SP)       // <--                                  // mov	qword ptr [rsp + 56], r14
	LEAQ  0(CX)(R14*1), AX    // <--                                  // lea	rax, [rcx + r14]
	INCQ  CX                  // <--                                  // inc	rcx
	IMULQ R9, CX              // <--                                  // imul	rcx, r9
	MOVQ  CX, 0x1a0(SP)       // <--                                  // mov	qword ptr [rsp + 416], rcx
	MOVQ  R9, CX              // <--                                  // mov	rcx, r9
	MOVQ  AX, 0x68(SP)        // <--                                  // mov	qword ptr [rsp + 104], rax
	IMULQ AX, CX              // <--                                  // imul	rcx, rax
	MOVQ  0x8(SP), R14        // <--                                  // mov	r14, qword ptr [rsp + 8]
	LEAQ  0(R14)(CX*4), AX    // <--                                  // lea	rax, [r14 + 4*rcx]
	MOVQ  AX, 0x50(SP)        // <--                                  // mov	qword ptr [rsp + 80], rax
	LEAQ  0(R8*4), AX         // <--                                  // lea	rax, [4*r8]
	MOVQ  AX, 0x48(SP)        // <--                                  // mov	qword ptr [rsp + 72], rax
	LEAQ  0(R9*4), DX         // <--                                  // lea	rdx, [4*r9]
	XORL  CX, CX              // <--                                  // xor	ecx, ecx
	MOVQ  DX, 0x60(SP)        // <--                                  // mov	qword ptr [rsp + 96], rdx
	MOVQ  0xb8(SP), R12       // <--                                  // mov	r12, qword ptr [rsp + 184]
	MOVQ  0xb0(SP), R10       // <--                                  // mov	r10, qword ptr [rsp + 176]
	MOVQ  0xa0(SP), BX        // <--                                  // mov	rbx, qword ptr [rsp + 160]
	MOVQ  0x98(SP), R15       // <--                                  // mov	r15, qword ptr [rsp + 152]
	MOVQ  0x90(SP), R13       // <--                                  // mov	r13, qword ptr [rsp + 144]
	JMP   LBB1_8              // <--                                  // jmp	.LBB1_8

LBB1_14:
	MOVQ 0x58(SP), CX // <--                                  // mov	rcx, qword ptr [rsp + 88]
	INCQ CX           // <--                                  // inc	rcx
	MOVQ 0x48(SP), AX // <--                                  // mov	rax, qword ptr [rsp + 72]
	ADDQ AX, 0x28(SP) // <--                                  // add	qword ptr [rsp + 40], rax
	ADDQ AX, SI       // <--                                  // add	rsi, rax
	CMPQ CX, 0x10(SP) // <--                                  // cmp	rcx, qword ptr [rsp + 16]
	MOVQ 0x20(SP), R9 // <--                                  // mov	r9, qword ptr [rsp + 32]
	JE   LBB1_27      // <--                                  // je	.LBB1_27

LBB1_8:
	MOVQ  CX, 0x58(SP) // <--                                  // mov	qword ptr [rsp + 88], rcx
	IMULQ R9, CX       // <--                                  // imul	rcx, r9
	MOVQ  CX, 0xc8(SP) // <--                                  // mov	qword ptr [rsp + 200], rcx
	MOVQ  0x50(SP), R8 // <--                                  // mov	r8, qword ptr [rsp + 80]
	MOVQ  0x8(SP), CX  // <--                                  // mov	rcx, qword ptr [rsp + 8]
	XORL  AX, AX       // <--                                  // xor	eax, eax
	MOVQ  SI, 0xd0(SP) // <--                                  // mov	qword ptr [rsp + 208], rsi
	JMP   LBB1_9       // <--                                  // jmp	.LBB1_9

LBB1_13:
	MOVQ 0xc8(SP), AX              // <--                                  // mov	rax, qword ptr [rsp + 200]
	MOVQ 0xd8(SP), DI              // <--                                  // mov	rdi, qword ptr [rsp + 216]
	LEAQ 0(DI)(AX*1), CX           // <--                                  // lea	rcx, [rdi + rax]
	MOVQ DI, AX                    // <--                                  // mov	rax, rdi
	MOVQ 0x40(SP), R14             // <--                                  // mov	r14, qword ptr [rsp + 64]
	LONG $0x117ac1c4; WORD $0x8e04 // VMOVSS X0, 0(R14)(CX*4)              // vmovss	dword ptr [r14 + 4*rcx], xmm0
	INCQ AX                        // <--                                  // inc	rax
	MOVQ 0xe0(SP), CX              // <--                                  // mov	rcx, qword ptr [rsp + 224]
	ADDQ $0x4, CX                  // <--                                  // add	rcx, 4
	ADDQ $0x4, R8                  // <--                                  // add	r8, 4
	CMPQ AX, 0x18(SP)              // <--                                  // cmp	rax, qword ptr [rsp + 24]
	JE   LBB1_14                   // <--                                  // je	.LBB1_14

LBB1_9:
	MOVQ AX, 0xd8(SP)  // <--                                  // mov	qword ptr [rsp + 216], rax
	MOVQ R8, 0xe8(SP)  // <--                                  // mov	qword ptr [rsp + 232], r8
	LONG $0xc057f8c5   // VXORPS X0, X0, X0                    // vxorps	xmm0, xmm0, xmm0
	MOVQ 0x28(SP), R14 // <--                                  // mov	r14, qword ptr [rsp + 40]
	MOVQ CX, 0xe0(SP)  // <--                                  // mov	qword ptr [rsp + 224], rcx
	MOVQ 0x38(SP), R9  // <--                                  // mov	r9, qword ptr [rsp + 56]
	LONG $0xc957f0c5   // VXORPS X1, X1, X1                    // vxorps	xmm1, xmm1, xmm1
	LONG $0xd257e8c5   // VXORPS X2, X2, X2                    // vxorps	xmm2, xmm2, xmm2
	LONG $0xdb57e0c5   // VXORPS X3, X3, X3                    // vxorps	xmm3, xmm3, xmm3
	MOVQ 0xa8(SP), DI  // <--                                  // mov	rdi, qword ptr [rsp + 168]
	MOVQ 0x88(SP), AX  // <--                                  // mov	rax, qword ptr [rsp + 136]
	MOVQ 0x80(SP), DX  // <--                                  // mov	rdx, qword ptr [rsp + 128]
	MOVQ 0x78(SP), SI  // <--                                  // mov	rsi, qword ptr [rsp + 120]
	MOVQ 0x70(SP), R8  // <--                                  // mov	r8, qword ptr [rsp + 112]

LBB1_10:
	LONG $0x2410fac5; BYTE $0x91               // VMOVSS 0(CX)(DX*4), X4               // vmovss	xmm4, dword ptr [rcx + 4*rdx]
	LONG $0x2159e3c4; WORD $0x8124; BYTE $0x10 // VINSERTPS $0x10, 0(CX)(AX*4), X4, X4 // vinsertps	xmm4, xmm4, dword ptr [rcx + 4*rax], 16
	LONG $0x2159a3c4; WORD $0xa924; BYTE $0x20 // VINSERTPS $0x20, 0(CX)(R13*4), X4, X4 // vinsertps	xmm4, xmm4, dword ptr [rcx + 4*r13], 32
	LONG $0x2159a3c4; WORD $0xb924; BYTE $0x30 // VINSERTPS $0x30, 0(CX)(R15*4), X4, X4 // vinsertps	xmm4, xmm4, dword ptr [rcx + 4*r15], 48
	MOVQ 0x198(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 408]
	LONG $0x107aa1c4; WORD $0x192c             // VMOVSS 0(CX)(R11*1), X5              // vmovss	xmm5, dword ptr [rcx + r11]
	MOVQ 0x1a0(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 416]
	LONG $0x2151a3c4; WORD $0x992c; BYTE $0x10 // VINSERTPS $0x10, 0(CX)(R11*4), X5, X5 // vinsertps	xmm5, xmm5, dword ptr [rcx + 4*r11], 16
	LONG $0x2151a3c4; WORD $0x812c; BYTE $0x20 // VINSERTPS $0x20, 0(CX)(R8*4), X5, X5 // vinsertps	xmm5, xmm5, dword ptr [rcx + 4*r8], 32
	LONG $0x2151e3c4; WORD $0xb12c; BYTE $0x30 // VINSERTPS $0x30, 0(CX)(SI*4), X5, X5 // vinsertps	xmm5, xmm5, dword ptr [rcx + 4*rsi], 48
	MOVQ 0xf0(SP), R11                         // <--                                  // mov	r11, qword ptr [rsp + 240]
	LONG $0x107aa1c4; WORD $0x9934             // VMOVSS 0(CX)(R11*4), X6              // vmovss	xmm6, dword ptr [rcx + 4*r11]
	MOVQ 0xf8(SP), R11                         // <--                                  // mov	r11, qword ptr [rsp + 248]
	LONG $0x2149a3c4; WORD $0x9934; BYTE $0x10 // VINSERTPS $0x10, 0(CX)(R11*4), X6, X6 // vinsertps	xmm6, xmm6, dword ptr [rcx + 4*r11], 16
	MOVQ 0x100(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 256]
	LONG $0x2149a3c4; WORD $0x9934; BYTE $0x20 // VINSERTPS $0x20, 0(CX)(R11*4), X6, X6 // vinsertps	xmm6, xmm6, dword ptr [rcx + 4*r11], 32
	MOVQ 0x108(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 264]
	LONG $0x2149a3c4; WORD $0x9934; BYTE $0x30 // VINSERTPS $0x30, 0(CX)(R11*4), X6, X6 // vinsertps	xmm6, xmm6, dword ptr [rcx + 4*r11], 48
	LONG $0x3c10fac5; BYTE $0x99               // VMOVSS 0(CX)(BX*4), X7               // vmovss	xmm7, dword ptr [rcx + 4*rbx]
	LONG $0x2141e3c4; WORD $0xb93c; BYTE $0x10 // VINSERTPS $0x10, 0(CX)(DI*4), X7, X7 // vinsertps	xmm7, xmm7, dword ptr [rcx + 4*rdi], 16
	LONG $0x2141a3c4; WORD $0x913c; BYTE $0x20 // VINSERTPS $0x20, 0(CX)(R10*4), X7, X7 // vinsertps	xmm7, xmm7, dword ptr [rcx + 4*r10], 32
	LONG $0x2141a3c4; WORD $0xa13c; BYTE $0x30 // VINSERTPS $0x30, 0(CX)(R12*4), X7, X7 // vinsertps	xmm7, xmm7, dword ptr [rcx + 4*r12], 48
	MOVQ 0x130(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 304]
	LONG $0x107a21c4; WORD $0x9904             // VMOVSS 0(CX)(R11*4), X8              // vmovss	xmm8, dword ptr [rcx + 4*r11]
	MOVQ 0x138(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 312]
	LONG $0x213923c4; WORD $0x9904; BYTE $0x10 // VINSERTPS $0x10, 0(CX)(R11*4), X8, X8 // vinsertps	xmm8, xmm8, dword ptr [rcx + 4*r11], 16
	MOVQ 0x140(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 320]
	LONG $0x213923c4; WORD $0x9904; BYTE $0x20 // VINSERTPS $0x20, 0(CX)(R11*4), X8, X8 // vinsertps	xmm8, xmm8, dword ptr [rcx + 4*r11], 32
	MOVQ 0x148(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 328]
	LONG $0x213923c4; WORD $0x9904; BYTE $0x30 // VINSERTPS $0x30, 0(CX)(R11*4), X8, X8 // vinsertps	xmm8, xmm8, dword ptr [rcx + 4*r11], 48
	MOVQ 0x110(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 272]
	LONG $0x107a21c4; WORD $0x990c             // VMOVSS 0(CX)(R11*4), X9              // vmovss	xmm9, dword ptr [rcx + 4*r11]
	MOVQ 0x118(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 280]
	LONG $0x213123c4; WORD $0x990c; BYTE $0x10 // VINSERTPS $0x10, 0(CX)(R11*4), X9, X9 // vinsertps	xmm9, xmm9, dword ptr [rcx + 4*r11], 16
	MOVQ 0x120(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 288]
	LONG $0x213123c4; WORD $0x990c; BYTE $0x20 // VINSERTPS $0x20, 0(CX)(R11*4), X9, X9 // vinsertps	xmm9, xmm9, dword ptr [rcx + 4*r11], 32
	LONG $0x1855e3c4; WORD $0x01e4             // VINSERTF128 $0x1, X4, Y5, Y4         // vinsertf128	ymm4, ymm5, xmm4, 1
	MOVQ 0x128(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 296]
	LONG $0x2131a3c4; WORD $0x992c; BYTE $0x30 // VINSERTPS $0x30, 0(CX)(R11*4), X9, X5 // vinsertps	xmm5, xmm9, dword ptr [rcx + 4*r11], 48
	MOVQ 0x170(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 368]
	LONG $0x107a21c4; WORD $0x990c             // VMOVSS 0(CX)(R11*4), X9              // vmovss	xmm9, dword ptr [rcx + 4*r11]
	MOVQ 0x178(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 376]
	LONG $0x213123c4; WORD $0x990c; BYTE $0x10 // VINSERTPS $0x10, 0(CX)(R11*4), X9, X9 // vinsertps	xmm9, xmm9, dword ptr [rcx + 4*r11], 16
	MOVQ 0x180(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 384]
	LONG $0x213123c4; WORD $0x990c; BYTE $0x20 // VINSERTPS $0x20, 0(CX)(R11*4), X9, X9 // vinsertps	xmm9, xmm9, dword ptr [rcx + 4*r11], 32
	LONG $0x1845e3c4; WORD $0x01f6             // VINSERTF128 $0x1, X6, Y7, Y6         // vinsertf128	ymm6, ymm7, xmm6, 1
	MOVQ 0x188(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 392]
	LONG $0x2131a3c4; WORD $0x993c; BYTE $0x30 // VINSERTPS $0x30, 0(CX)(R11*4), X9, X7 // vinsertps	xmm7, xmm9, dword ptr [rcx + 4*r11], 48
	MOVQ 0x150(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 336]
	LONG $0x107a21c4; WORD $0x990c             // VMOVSS 0(CX)(R11*4), X9              // vmovss	xmm9, dword ptr [rcx + 4*r11]
	MOVQ 0x158(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 344]
	LONG $0x213123c4; WORD $0x990c; BYTE $0x10 // VINSERTPS $0x10, 0(CX)(R11*4), X9, X9 // vinsertps	xmm9, xmm9, dword ptr [rcx + 4*r11], 16
	MOVQ 0x160(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 352]
	LONG $0x213123c4; WORD $0x990c; BYTE $0x20 // VINSERTPS $0x20, 0(CX)(R11*4), X9, X9 // vinsertps	xmm9, xmm9, dword ptr [rcx + 4*r11], 32
	LONG $0x1855c3c4; WORD $0x01e8             // VINSERTF128 $0x1, X8, Y5, Y5         // vinsertf128	ymm5, ymm5, xmm8, 1
	MOVQ 0x168(SP), R11                        // <--                                  // mov	r11, qword ptr [rsp + 360]
	LONG $0x213123c4; WORD $0x9904; BYTE $0x30 // VINSERTPS $0x30, 0(CX)(R11*4), X9, X8 // vinsertps	xmm8, xmm9, dword ptr [rcx + 4*r11], 48
	LONG $0x183de3c4; WORD $0x01ff             // VINSERTF128 $0x1, X7, Y8, Y7         // vinsertf128	ymm7, ymm8, xmm7, 1
	LONG $0xb85dc2c4; WORD $0xa046             // VFMADD231PS -0x60(R14), Y4, Y0       // vfmadd231ps	ymm0, ymm4, ymmword ptr [r14 - 96]
	LONG $0xb84dc2c4; WORD $0xc04e             // VFMADD231PS -0x40(R14), Y6, Y1       // vfmadd231ps	ymm1, ymm6, ymmword ptr [r14 - 64]
	LONG $0xb855c2c4; WORD $0xe056             // VFMADD231PS -0x20(R14), Y5, Y2       // vfmadd231ps	ymm2, ymm5, ymmword ptr [r14 - 32]
	LONG $0xb845c2c4; BYTE $0x1e               // VFMADD231PS 0(R14), Y7, Y3           // vfmadd231ps	ymm3, ymm7, ymmword ptr [r14]
	ADDQ 0x190(SP), CX                         // <--                                  // add	rcx, qword ptr [rsp + 400]
	SUBQ $-0x80, R14                           // <--                                  // sub	r14, -128
	ADDQ $-0x20, R9                            // <--                                  // add	r9, -32
	JNE  LBB1_10                               // <--                                  // jne	.LBB1_10
	LONG $0xc058f4c5                           // VADDPS Y0, Y1, Y0                    // vaddps	ymm0, ymm1, ymm0
	LONG $0xca58e4c5                           // VADDPS Y2, Y3, Y1                    // vaddps	ymm1, ymm3, ymm2
	LONG $0xc058f4c5                           // VADDPS Y0, Y1, Y0                    // vaddps	ymm0, ymm1, ymm0
	LONG $0x197de3c4; WORD $0x01c1             // VEXTRACTF128 $0x1, Y0, X1            // vextractf128	xmm1, ymm0, 1
	LONG $0xc158f8c5                           // VADDPS X1, X0, X0                    // vaddps	xmm0, xmm0, xmm1
	LONG $0xc8c6f9c5; BYTE $0x01               // VSHUFPD $0x1, X0, X0, X1             // vshufpd	xmm1, xmm0, xmm0, 1
	LONG $0xc158f8c5                           // VADDPS X1, X0, X0                    // vaddps	xmm0, xmm0, xmm1
	LONG $0xc816fac5                           // VMOVSHDUP X0, X1                     // vmovshdup	xmm1, xmm0
	LONG $0xc158fac5                           // VADDSS X1, X0, X0                    // vaddss	xmm0, xmm0, xmm1
	MOVQ 0xe8(SP), R8                          // <--                                  // mov	r8, qword ptr [rsp + 232]
	MOVQ R8, CX                                // <--                                  // mov	rcx, r8
	MOVQ 0x68(SP), R9                          // <--                                  // mov	r9, qword ptr [rsp + 104]
	MOVQ 0xc0(SP), DI                          // <--                                  // mov	rdi, qword ptr [rsp + 192]
	CMPQ DI, 0x38(SP)                          // <--                                  // cmp	rdi, qword ptr [rsp + 56]
	MOVQ 0xd0(SP), SI                          // <--                                  // mov	rsi, qword ptr [rsp + 208]
	MOVQ 0x30(SP), DI                          // <--                                  // mov	rdi, qword ptr [rsp + 48]
	MOVQ 0x60(SP), DX                          // <--                                  // mov	rdx, qword ptr [rsp + 96]
	JE   LBB1_13                               // <--                                  // je	.LBB1_13

LBB1_12:
	LONG $0x0910fac5               // VMOVSS 0(CX), X1                     // vmovss	xmm1, dword ptr [rcx]
	LONG $0xb971a2c4; WORD $0x8e04 // VFMADD231SS 0(SI)(R9*4), X1, X0      // vfmadd231ss	xmm0, xmm1, dword ptr [rsi + 4*r9]
	INCQ R9                        // <--                                  // inc	r9
	ADDQ DX, CX                    // <--                                  // add	rcx, rdx
	CMPQ DI, R9                    // <--                                  // cmp	rdi, r9
	JNE  LBB1_12                   // <--                                  // jne	.LBB1_12
	JMP  LBB1_13                   // <--                                  // jmp	.LBB1_13
